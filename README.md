# Автоматизация и оркестрация ML-пайплайна с Apache Airflow

## Цель проекта

Разработка и автоматизация воспроизводимого пайплайна машинного обучения для классификации опухолей молочной железы (доброкачественные / злокачественные) на основе медицинских данных с использованием **Apache Airflow** и **облачного хранилища**.

## Формулировка ML-задачи

Тип задачи: **бинарная классификация**  
Классы:
- `M` — злокачественная опухоль
- `B` — доброкачественная опухоль

Используемая модель: `LogisticRegression`  
Метрики качества: `Accuracy`, `Precision`, `Recall`, `F1-score`

## Архитектура пайплайна

```mermaid
graph TD
    A[Загрузка данных] --> B[Предобработка данных]
    B --> C[Обучение модели]
    C --> D[Оценка модели]
    D --> E[Сохранение результатов]
```

## Структура проекта

```plaintext
project/
├── dags/
│   └── pipeline_dag.py         # DAG-файл Airflow
├── etl/
│   ├── load_data.py            # Загрузка и первичный анализ
│   ├── preprocess.py           # Очистка и подготовка
│   ├── train_model.py          # Обучение модели
│   ├── evaluate.py             # Оценка качества
│   └── save_results.py         # Сохранение артефактов
├── results/                    # Финальные артефакты
├── logs/                       # Логи выполнения DAG
├── config.yaml                 # Конфигурация пайплайна
├── .env                        # Переменные окружения
├── requirements.txt            # Зависимости
└── README.md                   # Документация проекта
```

## Этапы пайплайна

| Этап             | Скрипт                 | Описание                                                       |
|------------------|------------------------|----------------------------------------------------------------|
| Загрузка данных  | `etl/load_data.py`     | Загрузка исходного CSV, базовая проверка и сохранение          |
| Предобработка    | `etl/preprocess.py`    | Очистка данных, нормализация, разбиение на train/test          |
| Обучение модели  | `etl/train_model.py`   | Обучение модели `LogisticRegression` и сохранение              |
| Оценка модели    | `etl/evaluate.py`      | Расчёт метрик: Accuracy, Precision, Recall, F1                 |
| Сохранение       | `etl/save_results.py`  | Сохранение модели и метрик локально или в облако               |


## Этап 2: Разработка ETL-компонентов

В этом этапе реализованы отдельные Python-скрипты, выполняющие этапы обработки данных, обучения и сохранения результатов. Все скрипты могут быть запущены как вручную, так и через Apache Airflow, принимают аргументы командной строки, и сохраняют промежуточные артефакты.

### `etl/load_data.py`
Загружает исходный CSV-файл (`wdbc.data.csv`), удаляет столбец `id`, задаёт названия признаков и сохраняет результат в `results/data_loaded.csv`.

### `etl/preprocess.py`
Осуществляет:
- кодировку меток (`M` → 1, `B` → 0),
- масштабирование признаков (`StandardScaler`),
- разбиение на `X_train`, `X_test`, `y_train`, `y_test`.

Сохраняет данные в `.pkl` формате в `results/`.

### `etl/train_model.py`
Обучает модель `LogisticRegression` на `X_train` и `y_train`.  
Сохраняет модель в `results/model.pkl`.

### `etl/evaluate.py`
Вычисляет метрики качества модели:
- Accuracy
- Precision
- Recall
- F1-score

Сохраняет метрики в `results/metrics.json`.

### `etl/save_results.py`
Финальный этап. Копирует итоговые артефакты (`model.pkl`, `metrics.json`) в папку `results/final/`, моделируя "выгрузку в хранилище". Готово для замены на облачную интеграцию при необходимости.

---

Все скрипты поддерживают передачу параметров через `argparse` и могут быть использованы в Airflow как задачи `PythonOperator`.